# 2025-ICLR-Dynamic-LLaVA- Efficient Multimodal Large Language Models via Dynamic Vision-Language Context Sparsification

## 背景

- 多模态大型语言模型虽然在视觉理解、推理和交互方面表现出色，但其推理阶段随着输出文本令牌数量增加，计算和内存消耗也呈递增趋势，尤其是在解码阶段。这种增长严重影响了MLLMs的推理效率。
- 现有的高效推理方法主要集中在预填充阶段减少视觉信息冗余，如减少图像令牌，但这种预填充阶段的效率提升会随着解码过程的进行而逐渐减弱，因为解码阶段的计算瓶颈逐渐转向了自回归生成的语言令牌。
- 传统的KV缓存压缩方法虽然在一定程度上减轻了GPU内存压力，但通常依赖历史KV缓存的选择，且无法同时提升预填充和无KV缓存解码阶段的效率，对多模态场景适应性差。

![image-20250428232442550](/Asserts/images/133405@2x.png)

> 该图显示，尽管视觉令牌的稀疏化在预填充阶段能显著节省资源，但随着更多输出文本令牌的生成，计算和内存开销仍然逐渐增加，且传统方法在解码阶段的效率优势减少。这一现象说明了仅仅减少图像令牌数量不能持续提升解码阶段的推理效率

## 目的

- 提出Dynamic-LLaVA，一个动态视听语言上下文稀疏化框架，旨在通过对视觉上下文和语言上下文的动态稀疏化，提升MLLMs在推理全过程中的计算和内存效率。
- 在预填充和解码阶段分别设计适配不同推理模式（预填充、无KV缓存解码、有KV缓存解码）的稀疏化策略，实现对视觉和语言令牌的动态选择和过滤，持续减少计算量和内存占用。
- 通过端到端训练使模型能够动态学习并调整保留的重要令牌，从而在保证理解和生成能力的前提下，大幅度降低资源消耗。
- 实验中，Dynamic-LLaVA能在预填充阶段减少约75%的计算，在解码阶段减少约50%的计算和GPU内存使用，同时维持甚至提升模型性能，具备实际应用潜力。

## 相关工作

### 2.1 令牌数量减少以提升MLLM效率

这一部分主要讨论了针对视觉令牌的稀疏化和高效视觉编码/投影器设计方法，这些方法试图通过减少输入给大语言模型的图像令牌数量，从而加速推理预填充阶段。

- **视觉上下文稀疏化**：如FastV等方法利用注意力矩阵筛选关键图像令牌，仅将部分视觉令牌输入LLM，极大减少图像令牌数。
- **高效视觉编码器/投影器**：通过改进视觉特征提取和投影过程，生成更少的视觉令牌。

尽管这类方法在预填充阶段取得了显著的效率提升，但文中指出随着生成过程进入解码阶段，效率优势逐渐减弱，因为解码阶段的主要计算瓶颈转向了自回归生成的文本令牌，视觉令牌减少对解码效率提升作用有限。作者的Dynamic-LLaVA框架通过同时动态稀疏视觉和语言上下文，实现了推理全过程（含预填充及解码阶段）的持续高效推理，突破了传统方法的不足。

### 2.2 LLM的KV缓存压缩以节省内存

- 传统方法依赖历史已生成的KV缓存子集，通过计算当前查询和历史缓存的注意力分数来选出关键激活，剔除低效KV缓存。
- Dynamic-LLaVA提出通过"在线KV缓存压缩"策略，即基于当前输出文本令牌的特征决定是否保留该令牌对应的KV激活，无需依赖历史KV缓存。这种策略使Dynamic-LLaVA不仅能在含KV缓存的解码阶段提升效率，也能在预填充和无KV缓存解码阶段实现计算和内存节省，这是传统KV缓存压缩方法无法做到的。

此外，Dynamic-LLaVA设计了专门针对不同推理模式，如预填充、解码含/不含KV缓存的稀疏化推理方案，具备更广泛的应用场景和更好的多模态适应性。

第二章在系统梳理了现有的视觉令牌稀疏化和KV缓存压缩技术的基础上，突出Dynamic-LLaVA的创新性——它动态兼顾视觉和语言上下文稀疏化，涵盖推理全过程，并具备在线KV缓存压缩能力，从而显著提升MLLM推理效率和资源利用率，有效解决了传统方法在解码阶段效率减弱的问题，并具备更好的多模态融合适应性.

## 方法

