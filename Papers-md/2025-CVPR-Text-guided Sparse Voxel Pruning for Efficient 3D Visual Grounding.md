# 2025-CVPR-Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding

这篇论文提出了一种名为 TSP3D 的高效单阶段 3D 视觉定位方法，旨在在自然语言引导下从点云中快速准确地定位目标物体。与以往基于点云或两阶段的方法不同，TSP3D 首次在该任务中引入了稀疏卷积多层架构，并设计了两个关键机制：文本引导剪枝（TGP）用于根据语言信息逐步删除无关体素，从而高效实现多模态特征交互；以及基于补全的加和（CBA）用于在目标信息被误删时自适应补全重要区域。实验表明，TSP3D 在多个基准数据集上同时实现了最优的准确率与最快的推理速度，显著提升了3D视觉定位任务的实用性与效率。

## 摘要

本文提出了一种用于3D视觉定位的高效多层卷积架构。传统的两阶段或基于点的方法难以满足实时推理的要求。受到多层全稀疏卷积架构在3D目标检测中取得成功的启发，我们旨在沿着这条技术路线构建一个新的3D视觉定位框架。然而，由于3D视觉定位任务中，3D场景表示应该与文本特征进行深度交互，而基于稀疏卷积的架构由于大量的voxel特征，使得这种交互效率低下。**为此，我们提出了文本引导剪枝(TGP)和基于补全的添加(CBA)，通过逐步区域剪枝和目标补全，以有效的方式深度融合3D场景表示和文本特征。具体来说，TGP迭代地稀疏化3D场景表示，从而通过交叉注意力有效地将voxel特征与文本特征进行交互。**为了减轻剪枝对精细几何信息的影响，CBA通过voxel补全自适应地修复过度剪枝的区域，计算开销可以忽略不计。与之前的单阶段方法相比，我们的方法实现了最高的推理速度，并且超过了之前最快的方法100%的FPS。即使与两阶段方法相比，我们的方法也实现了最先进的精度，在ScanRefer上Acc@0.5的领先优势为+1.13，在NR3D和SR3D上分别领先+2.6和+3.2。代码可在https://github.com/GWxuan/TSP3D上获得。

## 1. Introduction

将多模态信息融入以指导3D视觉感知是一个很有前景的方向。近年来，3D视觉定位(3DVG)，也称为3D实例引用，作为一种基础的多模态3D感知任务，受到了越来越多的关注。3DVG的目标是用自由形式的查询描述来定位场景中的一个物体。3DVG具有挑战性，因为它需要理解3D场景和语言描述。最近，随着3D场景感知和视觉-语言模型的发展，3DVG方法已经取得了显著的进展。然而，由于3DVG被广泛应用于机器人和AR/VR等领域，在这些领域中，推理速度是主要的瓶颈，因此如何构建高效的实时3DVG模型仍然是一个具有挑战性的问题。

由于3DVG的输出格式与3D目标检测相似，早期的3DVG方法通常采用两阶段框架，首先进行检测以定位场景中的所有物体，然后通过结合文本信息来选择目标物体。由于3D目标检测和3DVG之间存在许多相似之处(例如，它们都需要提取3D场景的表示)，因此在独立采用这两种模型时，会产生大量的冗余特征计算。因此，两阶段方法通常难以处理实时任务。为了解决这个问题，提出了单阶段方法，该方法直接从点云生成目标的bounding box。这种集成设计更加紧凑和高效。然而，当前单阶段3DVG方法主要建立在基于点的架构之上，其中特征提取包含诸如最远点采样和kNN等耗时操作。他们还需要积极地对点特征进行下采样以降低计算成本，这可能会损害小而薄物体的几何信息。由于这些原因，当前的单阶段方法仍然远未达到实时（＜6 FPS），并且它们的性能不如两阶段方法，如图1所示。

在本文中，我们提出了一种新的基于文本引导的稀疏体素剪枝的3DVG单阶段框架，即TSP3D。受到最先进的3D目标检测方法的启发，该方法通过多层稀疏卷积架构实现了领先的精度和速度，我们构建了第一个稀疏单阶段3DVG网络。然而，与3D目标检测不同，在3DVG中，3D场景表示应该与文本特征进行深度交互。由于基于稀疏卷积的架构中的体素数量非常大，因此诸如交叉注意力之类的深度多模态交互由于无法承受的计算成本而变得不可行。为此，我们提出了文本引导剪枝（TGP），该方法首先利用文本信息来共同稀疏化3D场景表示并增强体素和文本特征。为了减轻剪枝对精细几何信息的影响，我们进一步提出了基于补全的添加（CBA）来自适应地修复过度剪枝的区域，而计算开销可忽略不计。具体来说，TGP根据对象分布修剪体素特征。它逐渐删除背景特征和不相关对象的特征，从而生成目标对象周围的文本感知体素特征，以实现精确的边界框预测。由于剪枝可能会错误地删除目标对象的表示，因此CBA利用文本特征从完整的骨干特征中查询一小组体素特征，然后进行剪枝感知添加以修复过度剪枝的区域。我们对流行的ScanRefer和ReferIt3D数据集进行了广泛的实验。与之前的单阶段方法相比，TSP3D实现了最高的推理速度，并且超过了之前最快的单阶段方法100％的FPS。即使与两阶段方法相比，TSP3D也实现了最先进的精度，在ScanRefer上Acc@0.5的领先优势为+1.13，在NR3D和SR3D上分别领先+2.6和+3.2。

总而言之，我们的主要贡献如下：

- 据我们所知，这是第一项探索用于有效3DVG的稀疏卷积架构的工作。
- 为了实现有效的特征提取，我们提出了文本引导剪枝和基于补全的添加来稀疏化稀疏体素并自适应地融合多层特征。
- 我们进行了广泛的实验，并且TSP3D在准确性和速度方面均优于现有方法，证明了所提出框架的优越性。